{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "37eb1f5d-41ec-4060-9f20-c28c37ec2b05",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "37eb1f5d-41ec-4060-9f20-c28c37ec2b05",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "79b7b4fe88b5ce1455d79a90e751565c",
          "grade": false,
          "grade_id": "cell-341078e8dde7e0e6",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# Text Generation using LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e84bca02-56b3-446d-a2b3-a35bcdfc0d34",
      "metadata": {
        "id": "e84bca02-56b3-446d-a2b3-a35bcdfc0d34"
      },
      "outputs": [],
      "source": [
        "skip_training = False   # You can set it to True if you want to run inference on your trained model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "598c309a-1cb0-490b-8eb3-8c0ad9441d32",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "598c309a-1cb0-490b-8eb3-8c0ad9441d32",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "31eca098bf738ae87c126a8dd4a7b28d",
          "grade": false,
          "grade_id": "cell-22ac2dd116c986e6",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Import the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e1996f4f-0290-4073-8f7a-47a30ea8d7c5",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "e1996f4f-0290-4073-8f7a-47a30ea8d7c5",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "fd6566ff374217876145e2ff34a74cae",
          "grade": false,
          "grade_id": "cell-8d754ffa5b6f36a3",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a87cd37b-67f9-4fc0-b745-fca21d3c36db",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "a87cd37b-67f9-4fc0-b745-fca21d3c36db",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "fd144beaefb5f28eeebf711a429118dc",
          "grade": false,
          "grade_id": "cell-1a5c0ed78b5fe3d7",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "47a13809-ab7e-4c19-b192-4d5109cad342"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "if torch.backends.mps.is_available():\n",
        "    device = torch.device('mps')\n",
        "else:\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66259c62-2979-4b9f-ad1f-bbc76e5bbd29",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "66259c62-2979-4b9f-ad1f-bbc76e5bbd29",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "e3f0f3acc67cf1db9005351e946bee4c",
          "grade": false,
          "grade_id": "cell-918dec79c2334ca9",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Load and Preprocess the Text Dataset\n",
        "\n",
        "We will be using *Alice's Adventures in Wonderland* by Lewis Carroll as our dataset. You can download it from [Project Gutenberg](https://www.gutenberg.org/):\n",
        "\n",
        "[Alice's Adventures in Wonderland by Lewis Carroll (Project Gutenberg Page)](https://www.gutenberg.org/ebooks/11) \\\n",
        "[Direct Text File Download](https://www.gutenberg.org/files/11/11-0.txt)\n",
        "\n",
        "I've chosen Alice's Adventures in Wonderland as a relatively small text to make training still manageable on a CPU."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07811d19-7527-445c-9fa3-0a423ab22f77",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "07811d19-7527-445c-9fa3-0a423ab22f77",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "f06c5177f35d548718750d8eed3f43c2",
          "grade": false,
          "grade_id": "cell-0e71c281d4cb17c5",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "#### Load the Dataset\n",
        "\n",
        "We start by loading the text dataset into Python. The dataset should be a plain text file. The first step is to load and inspect a small portion of the raw text to understand its structure to identify any unwanted metadata or special characters that should be removed during preprocessing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39b5e555-045e-4f8f-8150-0f0b69cce823",
      "metadata": {
        "id": "39b5e555-045e-4f8f-8150-0f0b69cce823"
      },
      "outputs": [],
      "source": [
        "txt_path = 'alice.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1536e4c-1437-432f-b332-ee9e366f34b7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1536e4c-1437-432f-b332-ee9e366f34b7",
        "outputId": "d69a436d-fe55-41e7-9941-852cfce23fb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===First 1500 characters before any processing:\n",
            "\n",
            "\n",
            "﻿The Project Gutenberg eBook of Alice's Adventures in Wonderland\n",
            "    \n",
            "This ebook is for the use of anyone anywhere in the United States and\n",
            "most other parts of the world at no cost and with almost no restrictions\n",
            "whatsoever. You may copy it, give it away or re-use it under the terms\n",
            "of the Project Gutenberg License included with this ebook or online\n",
            "at www.gutenberg.org. If you are not located in the United States,\n",
            "you will have to check the laws of the country where you are located\n",
            "before using this eBook.\n",
            "\n",
            "Title: Alice's Adventures in Wonderland\n",
            "\n",
            "Author: Lewis Carroll\n",
            "\n",
            "Release date: June 27, 2008 [eBook #11]\n",
            "                Most recently updated: October 21, 2024\n",
            "\n",
            "Language: English\n",
            "\n",
            "Credits: Arthur DiBianca and David Widger\n",
            "\n",
            "\n",
            "*** START OF THE PROJECT GUTENBERG EBOOK ALICE'S ADVENTURES IN WONDERLAND ***\n",
            "[Illustration]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Alice’s Adventures in Wonderland\n",
            "\n",
            "by Lewis Carroll\n",
            "\n",
            "THE MILLENNIUM FULCRUM EDITION 3.0\n",
            "\n",
            "Contents\n",
            "\n",
            " CHAPTER I.     Down the Rabbit-Hole\n",
            " CHAPTER II.    The Pool of Tears\n",
            " CHAPTER III.   A Caucus-Race and a Long Tale\n",
            " CHAPTER IV.    The Rabbit Sends in a Little Bill\n",
            " CHAPTER V.     Advice from a Caterpillar\n",
            " CHAPTER VI.    Pig and Pepper\n",
            " CHAPTER VII.   A Mad Tea-Party\n",
            " CHAPTER VIII.  The Queen’s Croquet-Ground\n",
            " CHAPTER IX.    The Mock Turtle’s Story\n",
            " CHAPTER X.     The Lobster Quadrille\n",
            " CHAPTER XI.    Who Stole the Tarts?\n",
            " CHAPTER XII.   Alice’s Evidence\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "CHAPTER I.\n",
            "Down the Rabbit-Hole\n",
            "\n",
            "\n",
            "Alice was beginning to get very tired of sitting by her sister on \n",
            "\n",
            "\n",
            "\n",
            "===Ending characters before any processing:\n",
            "\n",
            "\n",
            "would, in the after-time, be herself a grown woman; and how she would\n",
            "keep, through all her riper years, the simple and loving heart of her\n",
            "childhood: and how she would gather about her other little children,\n",
            "and make _their_ eyes bright and eager with many a strange tale,\n",
            "perhaps even with the dream of Wonderland of long ago: and how she\n",
            "would feel with all their simple sorrows, and find a pleasure in all\n",
            "their simple joys, remembering her own child-life, and the happy summer\n",
            "days.\n",
            "\n",
            "THE END\n",
            "\n",
            "\n",
            "\n",
            "*** END OF THE PROJECT GUTENBERG EBOOK ALICE'S ADVENTURES IN WONDERLAND ***\n",
            "\n",
            "\n",
            "    \n",
            "\n",
            "Updated editions will replace the previous one—the old editions will\n",
            "be renamed.\n",
            "\n",
            "Creating the works from print editions not protected by U.S. copyright\n",
            "law means that no one owns a United States copyright in these works,\n",
            "so the Foundation (and you!) can copy and distribute it in the United\n",
            "States without permission and without paying copyright\n",
            "royalties. Special rules, set forth in the General Terms of Use part\n",
            "of this license, apply to copying and distributing Project\n",
            "Gutenberg™ electronic works to protect the PROJECT GUTENBERG™\n",
            "concept and trademark. Project Gutenberg is a registered trademark,\n",
            "and may not be used if you charge for an eBook, except by following\n",
            "the terms of the trademark license, including paying royalties for use\n",
            "of the Project Gutenberg trademark. If you do not charge anything for\n",
            "copies of this eBook, complying with the trademark license is very\n",
            "easy. You may use this eBook for nearly any purpose such as creation\n",
            "of derivative works, reports, performances and research. Project\n",
            "Gutenberg eBooks may be modified and printed and given away—you may\n",
            "do practically ANYTHING in the United States with eBooks not protected\n",
            "by U.S. copyright law. Redistribution is subject to the trademark\n",
            "license, especially commercial redistribution.\n",
            "\n",
            "\n",
            "START: FULL LICENSE\n",
            "\n",
            "THE FULL PROJECT GUTENBERG LICENSE\n",
            "\n",
            "PLEASE READ THIS BEFORE YOU DISTRIBUTE OR USE THIS WORK\n",
            "\n",
            "To protect the Project Gutenberg\n"
          ]
        }
      ],
      "source": [
        "\n",
        "with open(txt_path, 'r', encoding = 'utf-8') as file:\n",
        "    raw_text = file.read()\n",
        "\n",
        "print('===First 1500 characters before any processing:\\n\\n')\n",
        "print(raw_text[:1500])\n",
        "\n",
        "print('\\n\\n\\n===Ending characters before any processing:\\n')\n",
        "print(raw_text[-19000:-17000])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32bfef24-0842-427c-aa49-2f01f36b8ff0",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "32bfef24-0842-427c-aa49-2f01f36b8ff0",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "0496274c867d0502435d160f36c14010",
          "grade": false,
          "grade_id": "cell-100dde1181de781c",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "#### Remove Metadata and Focus on the Main Text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fce77de-0ccd-40b1-ac63-3ebff4c9f8ab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fce77de-0ccd-40b1-ac63-3ebff4c9f8ab",
        "outputId": "5e309a02-4d97-412d-e07c-ac4d6a89ba68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===Text after removing metadata:\n",
            "\n",
            "CHAPTER I.\n",
            "Down the Rabbit-Hole\n",
            "\n",
            "\n",
            "Alice was beginning to get very tired of sitting by her sister on the\n",
            "bank, and of having nothing to do: once or twice she had peeped into\n",
            "the book her sister was reading, but it had no pictures or\n",
            "conversations in it, “and what is the use of a book,” thought Alice\n",
            "“without pictures or conversations?”\n",
            "\n",
            "So she was considering in her own mind (as well as she could, for the\n",
            "hot day made her feel very sleepy and stupid), whether the pleasure of\n",
            "making a daisy-chain would be worth the trouble of getting up and\n",
            "picking the daisies, when suddenly a White Rabbit with pink eyes ran\n",
            "close by her.\n",
            "\n",
            "There was nothing so _very_ remarkable in that; nor did Alice think it\n",
            "so _very_ much out of the way to hear the Rabbit say to itself, “Oh\n",
            "dear! Oh dear! I shall be late!” (when she thought it over afterwards,\n",
            "it occurred to her that she ought to have wondered at this, but at the\n",
            "time it all seemed quite natural); but when the Rabbit actually _took a\n",
            "watch out of its waistcoat-pocket_, and looked at it, and then hurried\n",
            "on, Alice started to her feet, for it flashed across her mind that she\n",
            "had never before seen a rabbit with either a waistcoat-pocket, or a\n",
            "watch to take out of it, and burning with curiosity, she ran across the\n",
            "field after it, and fortunately was just in time to see it pop down a\n",
            "large rabbit-hole under the hedge.\n",
            "\n",
            "In another moment down went Alice after it, never once considering how\n",
            "in the world she was to get out again.\n",
            "\n",
            "The rabbit-hole wen\n"
          ]
        }
      ],
      "source": [
        "# For this example, I'm removing everything before 'CHAPTER I.\\nDown the Rabbit-Hole'\n",
        "# and after the end marker\n",
        "start_index = raw_text.find('CHAPTER I.\\nDown the Rabbit-Hole')\n",
        "\n",
        "end_index = raw_text.find('*** END OF THE PROJECT GUTENBERG') # closing markers of Project Gutenberg\n",
        "\n",
        "trimmed_text = raw_text[start_index:end_index]\n",
        "\n",
        "print('===Text after removing metadata:\\n')\n",
        "print(trimmed_text[:1500])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "607662e4-b640-4aeb-9bf6-3ee5fca989ab",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "607662e4-b640-4aeb-9bf6-3ee5fca989ab",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "d9b89e7035c671d5a4ac7fbed1f53d92",
          "grade": false,
          "grade_id": "cell-ee8493145fa5be43",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "#### Clean the Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f910909e-acba-45f9-ac49-41c0d3432129",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "id": "f910909e-acba-45f9-ac49-41c0d3432129",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "1f65b86777609239806c103b9d5d4933",
          "grade": false,
          "grade_id": "cell-6e2568640b9031df",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "outputId": "89f0f152-bba3-44ba-aab6-5180ab38223b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text after cleaning and converting to lowercase:\n",
            "\n",
            "chapter i down the rabbit hole alice was beginning to get very tired of sitting by her sister on the bank and of having nothing to do once or twice she had peeped into the book her sister was reading but it had no pictures or conversations in it and what is the use of a book thought alice without pictures or conversations so she was considering in her own mind as well as she could for the hot day made her feel very sleepy and stupid whether the pleasure of making a daisy chain would be worth the trouble of getting up and picking the daisies when suddenly a white rabbit with pink eyes ran close by her there was nothing so very remarkable in that nor did alice think it so very much out of the way to hear the rabbit say to itself oh dear oh dear i shall be late when she thought it over afterwards it occurred to her that she ought to have wondered at this but at the time it all seemed quite natural but when the rabbit actually took a watch out of its waistcoat pocket and looked at it and t\n"
          ]
        }
      ],
      "source": [
        "def preprocess_text(text):\n",
        "   \n",
        "    lowered_text=text.lower()\n",
        "    lowered_text = re.sub(r'[^a-z0-9\\s]', ' ', lowered_text)\n",
        "    cleaned_text = re.sub(r'\\s+', ' ', lowered_text)\n",
        "\n",
        "\n",
        "    return cleaned_text\n",
        "\n",
        "cleaned_text = preprocess_text(trimmed_text)\n",
        "print('Text after cleaning and converting to lowercase:\\n')\n",
        "print(cleaned_text[:1000])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7b05133-4168-459e-8e36-2ec88d2ad51d",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "e7b05133-4168-459e-8e36-2ec88d2ad51d",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "6a920af1dea881be0da01e7f1013c338",
          "grade": false,
          "grade_id": "cell-ae2039f6bc91f976",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Character-Level Encoding\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a820382-8e61-4d1c-a0b5-588d81b58320",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "4a820382-8e61-4d1c-a0b5-588d81b58320",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "bc5b454add8e5408a13c0010452fe78a",
          "grade": false,
          "grade_id": "cell-02de74b25a6da964",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "#### Character-Level Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64011399-7d6d-4cb3-89e8-fa65653a5a72",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "id": "64011399-7d6d-4cb3-89e8-fa65653a5a72",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "02558911a39ac511871aa6e2c60fe160",
          "grade": false,
          "grade_id": "cell-d2e35b87ae8fa70e",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "outputId": "bc4e2be9-c1a5-419c-fa25-d7d73945a761"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Character to Integer Mapping:\n",
            "' ' : 0\n",
            "'a' : 1\n",
            "'b' : 2\n",
            "'c' : 3\n",
            "'d' : 4\n",
            "'e' : 5\n",
            "'f' : 6\n",
            "'g' : 7\n",
            "'h' : 8\n",
            "'i' : 9\n",
            "'j' : 10\n",
            "'k' : 11\n",
            "'l' : 12\n",
            "'m' : 13\n",
            "'n' : 14\n",
            "'o' : 15\n",
            "'p' : 16\n",
            "'q' : 17\n",
            "'r' : 18\n",
            "'s' : 19\n",
            "'t' : 20\n",
            "'u' : 21\n",
            "'v' : 22\n",
            "'w' : 23\n",
            "'x' : 24\n",
            "'y' : 25\n",
            "'z' : 26\n"
          ]
        }
      ],
      "source": [
        "def create_char_mappings(cleaned_text):\n",
        "    \n",
        "    dico = sorted(set(cleaned_text))\n",
        "    char_to_int = {char: idx for idx, char in enumerate(dico)}\n",
        "    int_to_char = {idx: char for char, idx in char_to_int.items()}\n",
        "\n",
        "    return char_to_int, int_to_char\n",
        "\n",
        "char_to_int, int_to_char = create_char_mappings(cleaned_text)\n",
        "print('Character to Integer Mapping:')\n",
        "for char, idx in list(char_to_int.items()):\n",
        "    print(f\"'{char}' : {idx}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c33f28d5-de30-4ffc-99cd-ee43a15926f8",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "c33f28d5-de30-4ffc-99cd-ee43a15926f8",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "5bd13e000e8dca85b863d1014c17d836",
          "grade": false,
          "grade_id": "cell-d3a464179b6eeffb",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "#### Encode the Text into Integers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af1aa404-54f9-4481-9e83-183f727b654e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "id": "af1aa404-54f9-4481-9e83-183f727b654e",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "8846a46a9d6bebdd3465d529c3f61cc2",
          "grade": false,
          "grade_id": "cell-82f52b40eea42a5c",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "outputId": "6f3df21d-d086-4ae5-ab7b-31ca4561810d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total encoded characters: 135002\n",
            "First 100 encoded characters:\n",
            "[3, 8, 1, 16, 20, 5, 18, 0, 9, 0, 4, 15, 23, 14, 0, 20, 8, 5, 0, 18, 1, 2, 2, 9, 20, 0, 8, 15, 12, 5, 0, 1, 12, 9, 3, 5, 0, 23, 1, 19, 0, 2, 5, 7, 9, 14, 14, 9, 14, 7, 0, 20, 15, 0, 7, 5, 20, 0, 22, 5, 18, 25, 0, 20, 9, 18, 5, 4, 0, 15, 6, 0, 19, 9, 20, 20, 9, 14, 7, 0, 2, 25, 0, 8, 5, 18, 0, 19, 9, 19, 20, 5, 18, 0, 15, 14, 0, 20, 8, 5]\n"
          ]
        }
      ],
      "source": [
        "def encode_text(cleaned_text, char_to_int):\n",
        "    \n",
        "    encoded_chars=[char_to_int[n] for n in cleaned_text]\n",
        "\n",
        "    return encoded_chars\n",
        "\n",
        "encoded_chars = encode_text(cleaned_text, char_to_int)\n",
        "print(f\"Total encoded characters: {len(encoded_chars)}\")\n",
        "print('First 100 encoded characters:')\n",
        "print(encoded_chars[:100])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c011421-7952-4c8d-8217-55c04e7d608f",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "6c011421-7952-4c8d-8217-55c04e7d608f",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "641539c878b4e707dad47e7bacdd6b7b",
          "grade": false,
          "grade_id": "cell-f6f0731068619a8c",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Batch Generation for Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afe5f57f-0bce-428d-8d46-67d71def6237",
      "metadata": {
        "deletable": false,
        "id": "afe5f57f-0bce-428d-8d46-67d71def6237",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d25f3054980fd9d9eec99685ebb48557",
          "grade": false,
          "grade_id": "cell-0c4e1828e13b2561",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "def get_batches(arr, batch_size, seq_length, step_size=None):\n",
        "    \n",
        "    if step_size is None:\n",
        "        step_size = seq_length\n",
        "    n=len(arr)\n",
        "    numberofbatches = (n-1 - seq_length) // (step_size * batch_size)\n",
        "    x_batches=[]\n",
        "    y_batches=[]\n",
        "    for i in range (numberofbatches):\n",
        "      x_batch=[]\n",
        "      y_batch=[]\n",
        "      for k in range(batch_size):\n",
        "        start=(step_size * batch_size) * i + k * step_size\n",
        "        end=start+seq_length\n",
        "\n",
        "        x_batch.append(arr[start:end])\n",
        "        y_batch.append(arr[start+1:end+1])\n",
        "      x_batches.append(x_batch)\n",
        "      y_batches.append(y_batch)\n",
        "    x_batches=np.array(x_batches)\n",
        "    y_batches=np.array(y_batches)\n",
        "\n",
        "\n",
        "\n",
        "    return x_batches, y_batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "c7e33b6e-b7f4-45c7-b3bc-14c80d71c4ef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "c7e33b6e-b7f4-45c7-b3bc-14c80d71c4ef",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4606767d6cce6b002bc2159704f63d3c",
          "grade": false,
          "grade_id": "cell-a063285239364470",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "956d60f8-54b6-44eb-b83b-09105ed5a563"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Displaying a Single Batch\n",
            "==================================================\n",
            "[made her f]  -->  [ade her fe]\n",
            "[her feel v]  -->  [er feel ve]\n",
            "[eel very s]  -->  [el very sl]\n",
            "[ery sleepy]  -->  [ry sleepy ]\n",
            "[leepy and ]  -->  [eepy and s]\n",
            "[ and stupi]  -->  [and stupid]\n",
            "[stupid whe]  -->  [tupid whet]\n",
            "[d whether ]  -->  [ whether t]\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# Display for y shift and  step_size\n",
        "def display_batch_generation(arr, char_to_int, int_to_char):\n",
        "    batch_size, seq_length, step_size = 8, 10, 5  # Setting step_size for overlap between sequences\n",
        "\n",
        "    x_batches, y_batches = get_batches(arr, batch_size, seq_length, step_size)\n",
        "\n",
        "    # Display batch number 10\n",
        "    x_chars = ''.join([int_to_char[idx] for idx in x_batches[10][0]])\n",
        "    y_chars = ''.join([int_to_char[idx] for idx in y_batches[10][0]])\n",
        "\n",
        "    print('='*50)\n",
        "    print('Displaying a Single Batch')\n",
        "    print('='*50)\n",
        "    for i in range(batch_size):\n",
        "        x_chars = ''.join([int_to_char[idx] for idx in x_batches[10][i]])\n",
        "        y_chars = ''.join([int_to_char[idx] for idx in y_batches[10][i]])\n",
        "\n",
        "        print(f\"[{x_chars}]  -->  [{y_chars}]\")\n",
        "    print('='*50)\n",
        "display_batch_generation(encoded_chars, char_to_int, int_to_char )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5662b3c-84f4-402e-a503-ffb1930fdeaa",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "b5662b3c-84f4-402e-a503-ffb1930fdeaa",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "b407aa7e91d942d51744bd8f60bb70cd",
          "grade": false,
          "grade_id": "cell-63d39ee7de5e409f",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Define the Character-Level LSTM Model \n",
        "\n",
        "[nn.LSTM](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html)\n",
        "[nn.Dropout](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html)\n",
        "[nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96e05ab1-1dc9-42cb-9e2a-aeb226861f5a",
      "metadata": {
        "deletable": false,
        "id": "96e05ab1-1dc9-42cb-9e2a-aeb226861f5a",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f38a50dd45898543c6efc37941ce9ce0",
          "grade": false,
          "grade_id": "cell-f08538e1fc0fcaff",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "class CharLSTM(nn.Module):\n",
        "    \n",
        "\n",
        "    def __init__(self, num_layers, input_dim, hidden_dim, output_dim, dropout_prob):\n",
        "        \n",
        "        super(CharLSTM, self).__init__()\n",
        "\n",
        "        # Save hidden dimension and number of layers for hidden state initialization\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size=input_dim,\n",
        "                            hidden_size=hidden_dim,\n",
        "                            num_layers=num_layers,\n",
        "                            dropout=dropout_prob,\n",
        "                            batch_first=True)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        \n",
        "        out, (h, c) = self.lstm(x, hidden)\n",
        "        out = self.dropout(out)\n",
        "        out = self.fc(out)\n",
        "\n",
        "\n",
        "        # Return the final output and the updated hidden states\n",
        "        return out, (h, c)\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        \n",
        "    \n",
        "        device = next(self.parameters()).device\n",
        "\n",
        "        # Initialize hidden state (h0) and cell state (c0) to zeros\n",
        "        \n",
        "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim, device=device)\n",
        "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim, device=device)\n",
        "\n",
        "\n",
        "        return (h0, c0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf5c3c04-852b-4fea-a96d-4440f1eca9f4",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "bf5c3c04-852b-4fea-a96d-4440f1eca9f4",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "04813018cf23bc6f0b88aecbd7e1257c",
          "grade": false,
          "grade_id": "cell-f811f0b42ac678b1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "#### Train the Model \n",
        "    [Adam_optimizer](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html)\n",
        "    [CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85869fef-cd2c-4f5f-a34f-21efd2995817",
      "metadata": {
        "deletable": false,
        "id": "85869fef-cd2c-4f5f-a34f-21efd2995817",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "c3bbd7de1795376183497192a382d6b9",
          "grade": false,
          "grade_id": "cell-12ea36dbb7f387ab",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "def train(model, encoded_chars, vocab_size, num_epochs, batch_size,\n",
        "          seq_length, step_size, learning_rate, save_path=None, verbose=True):\n",
        "\n",
        "    model.train()  \n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)  \n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Prepare batches\n",
        "    x_batches, y_batches = get_batches(encoded_chars, batch_size, seq_length, step_size)\n",
        "    num_batches = len(x_batches)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        # Progress bar for the current epoch\n",
        "        batch_loader = tqdm(zip(x_batches, y_batches), total=num_batches,\n",
        "                            leave=True, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
        "\n",
        "        # Initialize hidden states for both LSTM layers\n",
        "        hidden=model.init_hidden(batch_size)\n",
        "\n",
        "\n",
        "        for x, y in batch_loader:\n",
        "            x = torch.as_tensor(x, dtype=torch.long).to(device)\n",
        "            y = torch.as_tensor(y, dtype=torch.long).to(device) # target\n",
        "\n",
        "            \n",
        "            x = F.one_hot(x, num_classes=vocab_size).float()\n",
        "\n",
        "            hidden = tuple(h.detach() for h in hidden)\n",
        "            hidden = tuple(h.to(device) for h in hidden)\n",
        "\n",
        "            logits, hidden = model(x, hidden)\n",
        "\n",
        "            logits = logits.reshape(-1, vocab_size)\n",
        "            y = y.reshape(-1)\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(logits, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        # Print the average loss for the current epoch\n",
        "        if verbose:\n",
        "            print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss / num_batches:.4f}')\n",
        "\n",
        "       \n",
        "        if save_path:\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            print(f'Your trained model at epoch {epoch} is saved successfully!')\n",
        "\n",
        "    return total_loss / num_batches"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f744f6c3-06a4-47a3-9c46-c2344c4e74ab",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "f744f6c3-06a4-47a3-9c46-c2344c4e74ab",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "78ba413d7fe1f539b5f90fc147ac112a",
          "grade": false,
          "grade_id": "cell-50b02537e194d303",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "#### Model Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "3b68e133-661b-4382-bd4e-b08d6046763e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "3b68e133-661b-4382-bd4e-b08d6046763e",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "011c42d8611231ab6fb2e68b52c437ee",
          "grade": false,
          "grade_id": "cell-b525be2767a548e0",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "4f4d8696-55e0-46c8-d031-29d8576e81fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CharLSTM(\n",
            "  (lstm): LSTM(27, 400, num_layers=2, batch_first=True, dropout=0.1)\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (fc): Linear(in_features=400, out_features=27, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "hidden_dim = 400\n",
        "dropout_prob=0.1\n",
        "num_layers=2\n",
        "vocab_size = len(char_to_int)\n",
        "model = CharLSTM(num_layers, vocab_size, hidden_dim, vocab_size, dropout_prob)\n",
        "model = model.to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c738f5ec-9833-495d-b3e1-c0b61d31dee6",
      "metadata": {
        "id": "c738f5ec-9833-495d-b3e1-c0b61d31dee6"
      },
      "outputs": [],
      "source": [
        "num_epochs = 50\n",
        "batch_size = 50\n",
        "seq_length=100\n",
        "step_size=100\n",
        "learning_rate=0.001\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "3b371bf3-bf59-4204-84ea-903fc8eeee9b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "3b371bf3-bf59-4204-84ea-903fc8eeee9b",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b5464fa40099ca9dcc93745f47a0421a",
          "grade": false,
          "grade_id": "cell-4f276ff242dea824",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "b071f017-f577-47cb-8a8d-6d47151c1412"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/50: 100%|██████████| 26/26 [00:01<00:00, 21.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50, Loss: 2.9128\n",
            "Your trained model at epoch 0 is saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/50: 100%|██████████| 26/26 [00:00<00:00, 31.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/50, Loss: 2.8064\n",
            "Your trained model at epoch 1 is saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/50: 100%|██████████| 26/26 [00:00<00:00, 31.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/50, Loss: 2.7896\n",
            "Your trained model at epoch 2 is saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/50: 100%|██████████| 26/26 [00:00<00:00, 31.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/50, Loss: 2.6627\n",
            "Your trained model at epoch 3 is saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/50: 100%|██████████| 26/26 [00:00<00:00, 31.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/50, Loss: 2.4589\n",
            "Your trained model at epoch 4 is saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/50: 100%|██████████| 26/26 [00:00<00:00, 31.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/50, Loss: 2.2765\n",
            "Your trained model at epoch 5 is saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/50: 100%|██████████| 26/26 [00:00<00:00, 30.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/50, Loss: 2.1813\n",
            "Your trained model at epoch 6 is saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/50: 100%|██████████| 26/26 [00:00<00:00, 31.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/50, Loss: 2.1024\n",
            "Your trained model at epoch 7 is saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/50: 100%|██████████| 26/26 [00:00<00:00, 30.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/50, Loss: 2.0280\n",
            "Your trained model at epoch 8 is saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/50: 100%|██████████| 26/26 [00:00<00:00, 30.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/50, Loss: 1.9598\n",
            "Your trained model at epoch 9 is saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11/50: 100%|██████████| 26/26 [00:00<00:00, 30.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11/50, Loss: 1.8994\n",
            "Your trained model at epoch 10 is saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12/50: 100%|██████████| 26/26 [00:00<00:00, 30.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12/50, Loss: 1.8422\n",
            "Your trained model at epoch 11 is saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13/50: 100%|██████████| 26/26 [00:00<00:00, 30.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13/50, Loss: 1.7882\n",
            "Your trained model at epoch 12 is saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14/50: 100%|██████████| 26/26 [00:00<00:00, 30.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14/50, Loss: 1.7362\n",
            "Your trained model at epoch 13 is saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15/50: 100%|██████████| 26/26 [00:00<00:00, 30.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15/50, Loss: 1.6894\n",
            "Your trained model at epoch 14 is saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16/50: 100%|██████████| 26/26 [00:00<00:00, 30.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16/50, Loss: 1.6487\n",
            "Your trained model at epoch 15 is saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 17/50: 100%|██████████| 26/26 [00:00<00:00, 30.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17/50, Loss: 1.6052\n",
            "Your trained model at epoch 16 is saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 18/50: 100%|██████████| 26/26 [00:00<00:00, 30.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18/50, Loss: 1.5659\n",
            "Your trained model at epoch 17 is saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 19/50: 100%|██████████| 26/26 [00:00<00:00, 29.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19/50, Loss: 1.5270\n",
            "Your trained model at epoch 18 is saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 20/50: 100%|██████████| 26/26 [00:00<00:00, 30.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20/50, Loss: 1.4932\n",
            "Your trained model at epoch 19 is saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 21/50: 100%|██████████| 26/26 [00:00<00:00, 30.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21/50, Loss: 1.4621\n",
            "Your trained model at epoch 20 is saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 22/50: 100%|██████████| 26/26 [00:00<00:00, 30.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22/50, Loss: 1.4316\n",
            "Your trained model at epoch 21 is saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 23/50: 100%|██████████| 26/26 [00:00<00:00, 30.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23/50, Loss: 1.4012\n",
            "Your trained model at epoch 22 is saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 24/50: 100%|██████████| 26/26 [00:00<00:00, 30.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24/50, Loss: 1.3753\n",
            "Your trained model at epoch 23 is saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 25/50: 100%|██████████| 26/26 [00:00<00:00, 30.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25/50, Loss: 1.3511\n",
            "Your trained model at epoch 24 is saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 26/50: 100%|██████████| 26/26 [00:00<00:00, 31.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26/50, Loss: 1.3297\n",
            "Your trained model at epoch 25 is saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 27/50: 100%|██████████| 26/26 [00:00<00:00, 31.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 27/50, Loss: 1.3015\n",
            "Your trained model at epoch 26 is saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 28/50: 100%|██████████| 26/26 [00:00<00:00, 31.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28/50, Loss: 1.2774\n",
            "Your trained model at epoch 27 is saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 29/50: 100%|██████████| 26/26 [00:00<00:00, 31.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29/50, Loss: 1.2551\n",
            "Your trained model at epoch 28 is saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 30/50: 100%|██████████| 26/26 [00:00<00:00, 31.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 30/50, Loss: 1.2311\n",
            "Your trained model at epoch 29 is saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 31/50: 100%|██████████| 26/26 [00:00<00:00, 31.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 31/50, Loss: 1.2071\n",
            "Your trained model at epoch 30 is saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 32/50: 100%|██████████| 26/26 [00:00<00:00, 31.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 32/50, Loss: 1.1848\n",
            "Your trained model at epoch 31 is saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 33/50: 100%|██████████| 26/26 [00:00<00:00, 31.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 33/50, Loss: 1.1633\n",
            "Your trained model at epoch 32 is saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 34/50: 100%|██████████| 26/26 [00:00<00:00, 31.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 34/50, Loss: 1.1410\n",
            "Your trained model at epoch 33 is saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 35/50: 100%|██████████| 26/26 [00:00<00:00, 32.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 35/50, Loss: 1.1192\n",
            "Your trained model at epoch 34 is saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 36/50: 100%|██████████| 26/26 [00:00<00:00, 31.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 36/50, Loss: 1.0945\n",
            "Your trained model at epoch 35 is saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 37/50: 100%|██████████| 26/26 [00:00<00:00, 29.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 37/50, Loss: 1.0745\n",
            "Your trained model at epoch 36 is saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 38/50: 100%|██████████| 26/26 [00:00<00:00, 31.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 38/50, Loss: 1.0526\n",
            "Your trained model at epoch 37 is saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 39/50: 100%|██████████| 26/26 [00:00<00:00, 32.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 39/50, Loss: 1.0363\n",
            "Your trained model at epoch 38 is saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 40/50: 100%|██████████| 26/26 [00:00<00:00, 32.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 40/50, Loss: 1.0200\n",
            "Your trained model at epoch 39 is saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 41/50: 100%|██████████| 26/26 [00:00<00:00, 32.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 41/50, Loss: 1.0023\n",
            "Your trained model at epoch 40 is saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 42/50: 100%|██████████| 26/26 [00:00<00:00, 32.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 42/50, Loss: 0.9786\n",
            "Your trained model at epoch 41 is saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 43/50: 100%|██████████| 26/26 [00:00<00:00, 32.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 43/50, Loss: 0.9568\n",
            "Your trained model at epoch 42 is saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 44/50: 100%|██████████| 26/26 [00:00<00:00, 32.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 44/50, Loss: 0.9414\n",
            "Your trained model at epoch 43 is saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 45/50: 100%|██████████| 26/26 [00:00<00:00, 32.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 45/50, Loss: 0.9216\n",
            "Your trained model at epoch 44 is saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 46/50: 100%|██████████| 26/26 [00:00<00:00, 33.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 46/50, Loss: 0.8936\n",
            "Your trained model at epoch 45 is saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 47/50: 100%|██████████| 26/26 [00:00<00:00, 32.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 47/50, Loss: 0.8675\n",
            "Your trained model at epoch 46 is saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 48/50: 100%|██████████| 26/26 [00:00<00:00, 32.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 48/50, Loss: 0.8448\n",
            "Your trained model at epoch 47 is saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 49/50: 100%|██████████| 26/26 [00:00<00:00, 32.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 49/50, Loss: 0.8264\n",
            "Your trained model at epoch 48 is saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 50/50: 100%|██████████| 26/26 [00:00<00:00, 33.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 50/50, Loss: 0.8013\n",
            "Your trained model at epoch 49 is saved successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "if not skip_training:\n",
        "    loss = train(\n",
        "        model=model,\n",
        "        encoded_chars=encoded_chars,\n",
        "        vocab_size=vocab_size,\n",
        "        num_epochs=num_epochs,\n",
        "        batch_size=batch_size,\n",
        "        seq_length=seq_length,\n",
        "        step_size=step_size,\n",
        "        learning_rate=learning_rate,\n",
        "        save_path='best_model.pth'\n",
        "    )\n",
        "else:\n",
        "    model.load_state_dict(torch.load('best_model.pth', weights_only=False, map_location=device))\n",
        "    print('Loaded weights from your saved model successfully!')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "338fcf4c-4b13-466f-bb2a-9fc79d276910",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "338fcf4c-4b13-466f-bb2a-9fc79d276910",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "5f4810bbcce1d9b751981d42d7cec2e3",
          "grade": false,
          "grade_id": "cell-2c5996453d5e58cb",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "### Text Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af09b58d-db73-438c-8146-2d3de3c7258c",
      "metadata": {
        "deletable": false,
        "id": "af09b58d-db73-438c-8146-2d3de3c7258c",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f150ea2ef8cc1bf48f64175bcab64bd2",
          "grade": false,
          "grade_id": "cell-f6a72e59083bfbfb",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "def generate_text(model, start_str, char_to_int, int_to_char, vocab_size, predict_len=100, temperature=1.0):\n",
        "    \n",
        "    model.eval()  \n",
        "\n",
        "    \n",
        "    input_seq = [char_to_int[char] for char in start_str]\n",
        "    input_seq = torch.tensor(input_seq).long().to(device).unsqueeze(0)  \n",
        "\n",
        "    hidden = model.init_hidden(1)  # Batch size of 1 for generating text\n",
        "\n",
        "    generated_text = start_str\n",
        "\n",
        "    with torch.no_grad():  \n",
        "        for _ in range(predict_len):\n",
        "\n",
        "            \n",
        "            x= F.one_hot(input_seq, num_classes=vocab_size).float()\n",
        "            output, hidden = model(x, hidden)\n",
        "            output = output[:, -1, :]\n",
        "            output=output/temperature\n",
        "\n",
        "\n",
        "            # Convert output to probabilities using softmax\n",
        "            probabilities = F.softmax(output, dim=-1).detach().cpu().numpy()\n",
        "\n",
        "            # Randomly sample based on the output probabilities\n",
        "            next_char_index = np.random.choice(range(vocab_size), p=probabilities.ravel())\n",
        "\n",
        "            # Add the predicted character to the generated text\n",
        "            next_char = int_to_char[next_char_index]\n",
        "            generated_text += next_char\n",
        "\n",
        "            # Update the input sequence\n",
        "            input_seq = torch.cat([input_seq[:, 1:], torch.tensor([[next_char_index]]).to(device)], dim=1)\n",
        "\n",
        "    return generated_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "cad2f2ef-fd10-484e-9824-aa90c90b1884",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cad2f2ef-fd10-484e-9824-aa90c90b1884",
        "outputId": "b4cd0e60-ef96-4630-a0ca-11be433b82ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "we re all of the whole plose to have her and the words said alice i didn t said the mock turtle these was no wish of i don t go no sure of the only would be of her hand and every onine had been parsing at the players all i ve to to do this time of the lobster to begin with you mo not i ll get me to shin the exceponere i was she what s the jury or eagle with alice was a little marked alice indorainy not to be at all say the mock turtle they were now and then to do so she began with a suppy said alice went on without to the three gardeners in her hand at the mock turtle they were now only the other but the mock turtle of the book the officed the end of the beginning to the blay and hand and they would no too mo no time so saving all the three gardeners so she began in a lougn and began in a great quistle theie watching the end of the same with a replied so alice replied the queen so said the other but the top of the execution when they growing so she began no began which she roon and no id you won\n"
          ]
        }
      ],
      "source": [
        "start_str = 'we re all '\n",
        "predict_len = 1000\n",
        "temperature = 0.5\n",
        "generated_text = generate_text(model,\n",
        "                               start_str,\n",
        "                               char_to_int,\n",
        "                               int_to_char,\n",
        "                               vocab_size,\n",
        "                               predict_len=predict_len,\n",
        "                               temperature=temperature)\n",
        "print(generated_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "829e4717",
      "metadata": {},
      "source": [
        "While LSTMs grasp the grammar well, they struggle with long-term coherence compared to modern Transformer architectures. This project demonstrates the fundamentals of sequence modeling."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
